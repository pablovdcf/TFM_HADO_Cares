# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

# This data should be in the path "src/hado/extras/datasets"

# RAW Data from MongoDB
hado_22:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO22
  load_args: 
    _id: False
  layer: raw

hado_21:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO21
  load_args: 
    _id: False
  layer: raw

hado_20:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO20
  load_args: 
    _id: False
  layer: raw

hado_19:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO19
  load_args: 
    _id: False
  layer: raw

hado_18:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO18
  load_args: 
    _id: False
  layer: raw

hado_17:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO17
  load_args: 
    _id: False
  layer: raw

# Preprocessing Data
strip_lower_hado_17:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_17.csv

strip_lower_hado_18:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_18.csv

strip_lower_hado_19:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_19.csv

strip_lower_hado_20:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_20.csv

strip_lower_hado_21:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_21.csv

strip_lower_hado_22:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_22.csv


# Processing Data
hado_concat:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/HADO_concat.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: raw_preprocessing

hado_clean:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/HADO_clean.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: raw_processing

hado_clean_na:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_clean_na.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_barthel_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_clean_barthel.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_ps_ecog_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_clean_ps_ecog.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_gds_fast_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_gds_fast.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_replaced_words:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_replaced_words.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_lat_lon:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_lat_lon.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_cleaned_sedation:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned_medication.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: final_processing

hado_cleaned_medication:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned_medication.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: final_processing

hado_categorized:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/data_categorized.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: final_processing

hado_final:
  type: pandas.CSVDataSet
  filepath: data/04_feature/hado_final.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: feature

# Modeling
hado_encoded:
  type: pandas.CSVDataSet
  filepath: data/04_feature/hado_encoded.csv
  save_args:
    sep: ","
    index: False
  load_args:
    sep: ","
    na_values: ["#NA", NA]
  layer: model

# DATA SPLIT X_train `preprocessed`
X_alta_train_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/X_alta_train_preprocessed.pkl
  backend: pickle
  layer: model

X_diag_train_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/X_diag_train_preprocessed.pkl
  backend: pickle
  layer: model

# DATA SPLIT Y_train
y_alta_train:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/y_alta_train.pkl
  backend: pickle
  layer: model

y_diag_train:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/y_diag_train.pkl
  backend: pickle
  layer: model

# DATA SPLIT test `preprocessed`
X_alta_test_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/X_alta_test_preprocessed.pkl
  backend: pickle
  layer: model

y_alta_test:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/y_test_alta.pkl
  backend: pickle

X_diag_test_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/X_test_diag_preprocessed.pkl
  backend: pickle
  layer: model

y_test_diagnosis:
  type: pickle.PickleDataSet
  filepath: data/05_model_input/y_test_diagnosis.pkl
  backend: pickle

# Classification and Regression Models
random_forest_model_alta:
  type: pickle.PickleDataSet
  filepath: data/06_models/RandomForest_alta_model.pkl
  versioned: true
  layer: model

random_forest_model_diag:
  type: pickle.PickleDataSet
  filepath: data/06_models/RandomForest_diag_model.pkl
  versioned: true
  layer: model

xgboost_model_alta:
  type: pickle.PickleDataSet
  filepath: data/06_models/XGBoost_alta_model.pkl
  versioned: true
  layer: model

xgboost_model_diag:
  type: pickle.PickleDataSet
  filepath: data/06_models/XGBoost_diag_model.pkl
  versioned: true
  layer: model

lightgbm_model_alta:
  type: pickle.PickleDataSet
  filepath: data/06_models/ligthgbm_alta_model.pkl
  versioned: true
  layer: model

lightgbm_model_diag:
  type: pickle.PickleDataSet
  filepath: data/06_models/ligthgbm_diag_model.pkl
  versioned: true
  layer: model

confusion_matrix_rf_alta_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_rf_alta_image.png

confusion_matrix_rf_diag_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_rf_diag_image.png

confusion_matrix_lgb_alta_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_lgb_alta_image.png

confusion_matrix_lgb_diag_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_lgb_diag_image.png

confusion_matrix_xgb_alta_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_xgb_alta_image.png

confusion_matrix_xgb_diag_image:
  type: kedro.extras.datasets.pillow.ImageDataSet
  filepath: data/07_model_output/confusion_matrix_xgb_diag_image.png