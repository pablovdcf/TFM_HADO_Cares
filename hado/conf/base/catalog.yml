# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

# This data should be in the path "src/hado/extras/datasets"

# RAW Data from MongoDB
hado_22:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO22
  load_args: 
    _id: False
  layer: raw

hado_21:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO21
  load_args: 
    _id: False
  layer: raw

hado_20:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO20
  load_args: 
    _id: False
  layer: raw

hado_19:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO19
  load_args: 
    _id: False
  layer: raw

hado_18:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO18
  load_args: 
    _id: False
  layer: raw

hado_17:
  type: hado.extras.datasets.custom_data_set.MongoDBDataSet
  uri: mongodb://localhost:27017
  database: HADO_raw
  collection: HADO17
  load_args: 
    _id: False
  layer: raw

# Preprocessing Data
strip_lower_hado_17:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_17.csv

strip_lower_hado_18:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_18.csv

strip_lower_hado_19:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_19.csv

strip_lower_hado_20:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_20.csv

strip_lower_hado_21:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_21.csv

strip_lower_hado_22:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/strip_lower_hado_22.csv


# Processing Data
hado_concat:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/HADO_concat.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: raw_preprocessing

hado_clean:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/HADO_clean.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: raw_processing

hado_clean_na:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_clean_na.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_replaced_words:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_replaced_words.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_cleaned:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: intermediate_processing

hado_cleaned_sedation:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned_medication.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: final_processing

hado_cleaned_medication:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/hado_cleaned_medication.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: final_processing

hado_categorized:
  type: pandas.CSVDataSet
  filepath: data/02_intermediate/data_categorized.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: final_processing

hado_final:
  type: pandas.CSVDataSet
  filepath: data/04_feature/hado_final.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: feature

# Modeling
hado_model:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/hado_model.csv
  save_args:
    sep: "^"
    index: False
  load_args:
    sep: "^"
    na_values: ["#NA", NA]
  layer: model

X_train_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/X_train_alta.pkl
  backend: pickle
  layer: model

y_train:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/y_train_alta.pkl
  backend: pickle
  layer: model

X_train_diagnosis:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/X_train_diagnosis.pkl
  backend: pickle
  layer: model

y_train_diagnosis:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/y_train_diagnosis.pkl
  backend: pickle
  layer: model

X_test_preprocessed:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/X_test_pkl
  backend: pickle
  layer: model

y_test:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/y_test_alta.pkl
  backend: pickle

X_test_diagnosis:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/X_test_diagnosis.pkl
  backend: pickle
  layer: model

y_test_diagnosis:
  type: pickle.PickleDataSet
  filepath: data/07_model_output/y_test_diagnosis.pkl
  backend: pickle

random_forest_model_alta:
  type: pickle.PickleDataSet
  filepath: data/06_models/RandomForest_model.pkl
  versioned: true
  layer: model

xgboost_model:
  type: pickle.PickleDataSet
  filepath: data/06_models/XGBoost_model.pkl
  versioned: true
  layer: model

lightgbm_model:
  type: pickle.PickleDataSet
  filepath: data/06_models/ligthgbm_model.pkl
  versioned: true
  layer: model